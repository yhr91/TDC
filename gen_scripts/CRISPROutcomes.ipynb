{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repair outcomes dataset\n",
    "\n",
    "Creating a dataset of guide sequences and associated repair outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mygene\n",
    "from scipy.stats import entropy\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First set up guide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataframe\n",
    "df = pd.read_csv('Leenay_bam_df.csv')\n",
    "controls = ['CDK9r', 'CDK9r80', 'CXCR4r', 'CXCR4r80', 'LEDGFr', 'LEDGFr80', 'NTC']\n",
    "all_donors = ['RL384-00015', 'RL384-00017', 'RL384-00018', 'RL384-00019',\n",
    "       'RL384-00020', 'RL384-00021', 'RL384-00022', 'RL384-00023',\n",
    "       'RL384-00024', 'RL384-00025', 'RL384-00026', 'RL384-00027',\n",
    "       'RL384-00028', 'RL384-00029', 'RL384-00033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "unique_genes = np.sort(np.unique([f.split('-')[0] for f in df['genename']]))\n",
    "df = df.drop_duplicates(subset='reference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now determine the targets for each sequence and put it all together as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guide_seq(ref_seq):\n",
    "    guide_seq = ref_seq[13:36]\n",
    "    if guide_seq[-2:] != 'GG':\n",
    "        print('incorrect alignment')\n",
    "        return -1\n",
    "    return guide_seq\n",
    "\n",
    "def count_frameshifts(count_df):\n",
    "    fs = []\n",
    "    for v in count_df.index:\n",
    "        if v == 'no variant': continue;\n",
    "        if v == 'Other': continue;\n",
    "        if v[:3] == 'SNV': continue;\n",
    "        indels = v.split(',') \n",
    "        checks = []\n",
    "        for x in indels:\n",
    "            checks.append(int(x.split(':')[1][:-1]) % 3 != 0)\n",
    "        if all(checks):\n",
    "            fs.append(v)\n",
    "            \n",
    "    return count_df.loc[fs].sum()\n",
    "\n",
    "def avg_indel_length(df, ins=False, dele=False):\n",
    "    lengths = defaultdict(int)\n",
    "\n",
    "    for x in get_indels(df, ins=ins, dele=dele):\n",
    "\n",
    "        l = x.split(':')[:-1]\n",
    "        if len(l)==1:\n",
    "            lengths[np.abs(int(l[0]))] += df.loc[x]\n",
    "\n",
    "    avg = 0\n",
    "    for k,v in lengths.items():\n",
    "        avg += k*v\n",
    "    try:\n",
    "        avg = avg/sum(lengths.values())\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return avg\n",
    "\n",
    "def check_read_count(df):\n",
    "    return df.sum() > 1000\n",
    "\n",
    "def get_indels(count_df, ins=False, dele=False):\n",
    "    if ins:\n",
    "        if dele:\n",
    "            return [v for v in count_df.index if v[-1]=='I' or v[-1]=='D']\n",
    "        else:\n",
    "            return [v for v in count_df.index if v[-1]=='I']\n",
    "    elif dele:\n",
    "        return [v for v in count_df.index if v[-1]=='D']\n",
    "    \n",
    "def get_entropy(count_df):\n",
    "    return entropy(count_df.loc[get_indels(count_df, True, True)])\n",
    "\n",
    "def update_metrics(counts_df, metrics, guide_seq, k=0):\n",
    "\n",
    "    for donor, donor_name in enumerate(counts_df.columns):\n",
    "        \n",
    "        donor_name = donor_name.split('_')[0]\n",
    "        metrics[guide_seq] = defaultdict(int)\n",
    "        donor_df = counts_df.iloc[:,donor]\n",
    "        \n",
    "        try: donor_df = donor_df.drop('no variant');\n",
    "        except: pass;\n",
    "\n",
    "        # remove sites with less than 1000 reads\n",
    "        if check_read_count(donor_df) == False:\n",
    "            continue\n",
    "\n",
    "        # indel count\n",
    "        all_outcomes = donor_df\n",
    "        num_indels = donor_df.loc[get_indels(donor_df, ins=True, dele=True)].sum()\n",
    "        num_ins = donor_df.loc[get_indels(donor_df, ins=True)].sum()\n",
    "        metrics[guide_seq]['Fraction_Insertions'] = \\\n",
    "                               num_ins/num_indels\n",
    "        \n",
    "        # insertion length\n",
    "        metrics[guide_seq]['Avg_Insertion_Length'] = \\\n",
    "                    avg_indel_length(donor_df, ins=True) \n",
    "        \n",
    "        # deletion length\n",
    "        metrics[guide_seq]['Avg_Deletion_Length'] = \\\n",
    "                    avg_indel_length(donor_df, dele=True)         \n",
    "\n",
    "        # entropy\n",
    "        metrics[guide_seq]['Indel_Diversity'] = \\\n",
    "                    get_entropy(donor_df)\n",
    "\n",
    "        # frameshifts\n",
    "        metrics[guide_seq]['Fraction_Frameshifts'] = \\\n",
    "                    count_frameshifts(donor_df)/donor_df.sum()\n",
    "        \n",
    "        # For each guideRNA we only look at one donor because the paper claims\n",
    "        # repair outcomes do not depend on donor\n",
    "        if donor >= k:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/turing1/0/yhr/torch/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/lfs/turing1/0/yhr/torch/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect alignment\n",
      "incorrect alignment\n",
      "incorrect alignment\n",
      "incorrect alignment\n",
      "incorrect alignment\n",
      "incorrect alignment\n",
      "incorrect alignment\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for gene in df['genename'].values:\n",
    "    \n",
    "    if gene[:3] == 'NTC':\n",
    "        continue\n",
    "    if gene[-3:] == 'r80':\n",
    "        continue\n",
    "    \n",
    "    # Get guide sequence\n",
    "    ref_seq = df[df['genename'] == gene]['reference'].values[0]\n",
    "    guide_seq = get_guide_seq(ref_seq)\n",
    "    \n",
    "    if guide_seq == -1: continue;\n",
    "    \n",
    "    # For each replicate\n",
    "    for repeat in glob.glob('./counts/counts-'+ gene + '-*.txt'):\n",
    "        counts_df = pd.read_csv(repeat)\n",
    "        \n",
    "        # Update the metrics\n",
    "        update_metrics(counts_df, metrics, guide_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics).T.dropna()\n",
    "metrics = metrics.reset_index().rename(columns={'index':'GuideSeq'})\n",
    "metrics.to_csv('metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in dataframe to make sure it's in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('metrics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fraction_Insertions', 'Avg_Insertion_Length', 'Avg_Deletion_Length',\n",
       "       'Indel_Diversity', 'Fraction_Frameshifts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
